{
 "metadata": {
  "kernelspec": {
   "language": "python",
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.12.12",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "sourceId": 21755,
     "databundleVersionId": 1475600,
     "sourceType": "competition"
    }
   ],
   "dockerImageVersionId": 31236,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook",
   "isGpuEnabled": true
  }
 },
 "nbformat_minor": 4,
 "nbformat": 4,
 "cells": [
  {
   "cell_type": "code",
   "source": "from PIL import Image\nimport os\nimport itertools\n\nimport torch\nimport torch.nn as nn\nimport torch.nn.init as init\nimport torchvision.transforms as transforms\n\nfrom torch.utils.data import Dataset, DataLoader",
   "metadata": {
    "trusted": true,
    "execution": {
     "iopub.status.busy": "2025-12-30T10:53:16.952591Z",
     "iopub.execute_input": "2025-12-30T10:53:16.952857Z",
     "iopub.status.idle": "2025-12-30T10:53:24.888723Z",
     "shell.execute_reply.started": "2025-12-30T10:53:16.952828Z",
     "shell.execute_reply": "2025-12-30T10:53:24.888034Z"
    }
   },
   "outputs": [],
   "execution_count": 2
  },
  {
   "cell_type": "code",
   "source": [
    "!pip install gdown\n",
    "import gdown\n",
    "url = 'https://drive.google.com/file/d/1SjGjrur5WWeEf7rEySzbqfgM6X10yI4h/view?usp=sharing'\n",
    "!gdown --id 1SjGjrur5WWeEf7rEySzbqfgM6X10yI4h -O U-Net.ckpt"
   ],
   "metadata": {
    "trusted": true,
    "execution": {
     "iopub.status.busy": "2025-12-30T10:58:44.607385Z",
     "iopub.execute_input": "2025-12-30T10:58:44.608114Z",
     "iopub.status.idle": "2025-12-30T10:59:05.587669Z",
     "shell.execute_reply.started": "2025-12-30T10:58:44.608085Z",
     "shell.execute_reply": "2025-12-30T10:59:05.586892Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "text": "Requirement already satisfied: gdown in /usr/local/lib/python3.12/dist-packages (5.2.0)\nRequirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.12/dist-packages (from gdown) (4.13.5)\nRequirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from gdown) (3.20.1)\nRequirement already satisfied: requests[socks] in /usr/local/lib/python3.12/dist-packages (from gdown) (2.32.5)\nRequirement already satisfied: tqdm in /usr/local/lib/python3.12/dist-packages (from gdown) (4.67.1)\nRequirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.12/dist-packages (from beautifulsoup4->gdown) (2.8)\nRequirement already satisfied: typing-extensions>=4.0.0 in /usr/local/lib/python3.12/dist-packages (from beautifulsoup4->gdown) (4.15.0)\nRequirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests[socks]->gdown) (3.4.4)\nRequirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests[socks]->gdown) (3.11)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests[socks]->gdown) (2.6.2)\nRequirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests[socks]->gdown) (2025.11.12)\nRequirement already satisfied: PySocks!=1.5.7,>=1.5.6 in /usr/local/lib/python3.12/dist-packages (from requests[socks]->gdown) (1.7.1)\n/usr/local/lib/python3.12/dist-packages/gdown/__main__.py:140: FutureWarning: Option `--id` was deprecated in version 4.3.1 and will be removed in 5.0. You don't need to pass it anymore to use a file ID.\n  warnings.warn(\nDownloading...\nFrom (original): https://drive.google.com/uc?id=1cE_xvREuB4azlA9pFTlxSZ0jSlw-lR05\nFrom (redirected): https://drive.google.com/uc?id=1cE_xvREuB4azlA9pFTlxSZ0jSlw-lR05&confirm=t&uuid=8785f559-9ddd-4c78-9b2d-ffd92f263d63\nTo: /kaggle/working/U-Net.ckpt\n100%|██████████████████████████████████████| 1.37G/1.37G [00:14<00:00, 94.1MB/s]\n",
     "output_type": "stream"
    }
   ],
   "execution_count": 22
  },
  {
   "cell_type": "markdown",
   "source": "## Model",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": "class Downsample(nn.Module):\n  \"\"\"\n  Downsample block for U-Net encoder (contracting path)\n  - Conv2d with stride=2 to reduce spatial dimensions by half\n  - InstanceNorm2d for normalization (optional, typically skipped in first layer)\n  - LeakyReLU activation\n  \"\"\"\n  def __init__(self, in_ch, out_ch, normalize=True, dropout=0.0):\n      super().__init__()\n      layers = [\n          nn.Conv2d(in_ch, out_ch, kernel_size=4, stride=2, padding=1, bias=False)\n      ]\n\n      if normalize:\n          layers.append(nn.InstanceNorm2d(out_ch))\n\n      layers.append(nn.LeakyReLU(0.2, inplace=True))\n\n      if dropout:\n          layers.append(nn.Dropout(dropout))\n\n      self.model = nn.Sequential(*layers)\n\n  def forward(self, x):\n      return self.model(x)",
   "metadata": {
    "trusted": true,
    "execution": {
     "iopub.status.busy": "2025-12-30T10:59:05.589594Z",
     "iopub.execute_input": "2025-12-30T10:59:05.589846Z",
     "iopub.status.idle": "2025-12-30T10:59:05.595609Z",
     "shell.execute_reply.started": "2025-12-30T10:59:05.589821Z",
     "shell.execute_reply": "2025-12-30T10:59:05.594803Z"
    }
   },
   "outputs": [],
   "execution_count": 23
  },
  {
   "cell_type": "code",
   "source": "class Upsample(nn.Module):\n    \"\"\"\n    Upsample block for U-Net decoder (expanding path)\n    - ConvTranspose2d with stride=2 to increase spatial dimensions by 2x\n    - InstanceNorm2d for normalization\n    - Dropout for regularization (optional)\n    - ReLU activation\n    \"\"\"\n    def __init__(self, in_ch, out_ch, dropout=0.0):\n        super().__init__()\n        layers = [\n            nn.ConvTranspose2d(in_ch, out_ch, kernel_size=4, stride=2, padding=1, bias=False),\n            nn.InstanceNorm2d(out_ch),\n            nn.ReLU(inplace=True)\n        ]\n\n        if dropout:\n            layers.append(nn.Dropout(dropout))\n\n        self.model = nn.Sequential(*layers)\n\n    def forward(self, x, skip_input):\n        x = self.model(x)\n        return torch.cat((x, skip_input), 1)\n",
   "metadata": {
    "trusted": true,
    "execution": {
     "iopub.status.busy": "2025-12-30T10:59:05.596519Z",
     "iopub.execute_input": "2025-12-30T10:59:05.596819Z",
     "iopub.status.idle": "2025-12-30T10:59:07.451748Z",
     "shell.execute_reply.started": "2025-12-30T10:59:05.596785Z",
     "shell.execute_reply": "2025-12-30T10:59:07.450798Z"
    }
   },
   "outputs": [],
   "execution_count": 24
  },
  {
   "cell_type": "code",
   "source": "class Generator(nn.Module):\n    \"\"\"\n    U-Net Generator for CycleGAN\n    Architecture: Encoder-Decoder with skip connections\n    Input: 3-channel image (RGB)\n    Output: 3-channel image (RGB)\n    \"\"\"\n    def __init__(self, in_ch=3, out_ch=3, base_ch=64):\n        super(Generator, self).__init__()\n\n        # Encoder (Contracting Path)\n        self.down1 = Downsample(in_ch, base_ch, normalize=False)      # 128x128\n        self.down2 = Downsample(base_ch, base_ch*2)                   # 64x64\n        self.down3 = Downsample(base_ch*2, base_ch*4)                 # 32x32\n        self.down4 = Downsample(base_ch*4, base_ch*8, dropout=0.5)    # 16x16\n        self.down5 = Downsample(base_ch*8, base_ch*8, dropout=0.5)    # 8x8\n        self.down6 = Downsample(base_ch*8, base_ch*8, dropout=0.5)    # 4x4\n        self.down7 = Downsample(base_ch*8, base_ch*8, dropout=0.5)    # 2x2\n\n        # Bottleneck\n        self.bottleneck = Downsample(base_ch*8, base_ch*8, normalize=False, dropout=0.5)  # 1x1\n\n        # Decoder (Expanding Path)\n        self.up1 = Upsample(base_ch*8, base_ch*8, dropout=0.5)        # 2x2\n        self.up2 = Upsample(base_ch*16, base_ch*8, dropout=0.5)       # 4x4\n        self.up3 = Upsample(base_ch*16, base_ch*8, dropout=0.5)       # 8x8\n        self.up4 = Upsample(base_ch*16, base_ch*8, dropout=0.5)       # 16x16\n        self.up5 = Upsample(base_ch*16, base_ch*4)                    # 32x32\n        self.up6 = Upsample(base_ch*8, base_ch*2)                     # 64x64\n        self.up7 = Upsample(base_ch*4, base_ch)                       # 128x128\n\n        # Final output layer\n        self.final = nn.Sequential(\n            nn.ConvTranspose2d(base_ch*2, out_ch, kernel_size=4, stride=2, padding=1),\n            nn.Tanh()  # Output in range [-1, 1]\n        )\n\n    def forward(self, x):\n        # Encoder with skip connections\n        d1 = self.down1(x)                # 128x128\n        d2 = self.down2(d1)               # 64x64\n        d3 = self.down3(d2)               # 32x32\n        d4 = self.down4(d3)               # 16x16\n        d5 = self.down5(d4)               # 8x8\n        d6 = self.down6(d5)               # 4x4\n        d7 = self.down7(d6)               # 2x2\n\n        # Bottleneck\n        bottleneck = self.bottleneck(d7)  # 1x1\n\n        # Decoder with skip connections (concatenate)\n        u1 = self.up1(bottleneck, d7)     # 2x2\n        u2 = self.up2(u1, d6)             # 4x4\n        u3 = self.up3(u2, d5)             # 8x8\n        u4 = self.up4(u3, d4)             # 16x16\n        u5 = self.up5(u4, d3)             # 32x32\n        u6 = self.up6(u5, d2)             # 64x64\n        u7 = self.up7(u6, d1)             # 128x128\n\n        # Final output\n        output = self.final(u7)           # 256x256\n\n        return output",
   "metadata": {
    "trusted": true,
    "execution": {
     "iopub.status.busy": "2025-12-30T10:59:07.454955Z",
     "iopub.execute_input": "2025-12-30T10:59:07.455565Z",
     "iopub.status.idle": "2025-12-30T10:59:08.511845Z",
     "shell.execute_reply.started": "2025-12-30T10:59:07.455538Z",
     "shell.execute_reply": "2025-12-30T10:59:08.510921Z"
    }
   },
   "outputs": [],
   "execution_count": 25
  },
  {
   "cell_type": "code",
   "source": "class Discriminator(nn.Module):\n    \"\"\"\n    PatchGAN Discriminator for CycleGAN\n    - Classifies whether overlapping image patches are real or fake\n    - Outputs a matrix of predictions rather than a single value\n    - Uses 70x70 receptive field (patch size)\n    \"\"\"\n    def __init__(self, in_ch=3, base_ch=64):\n        super(Discriminator, self).__init__()\n\n        def conv_block(in_features, out_features, normalize=True):\n            layers = [nn.Conv2d(in_features, out_features, kernel_size=4, stride=2, padding=1)]\n            if normalize:\n                layers.append(nn.InstanceNorm2d(out_features))\n            layers.append(nn.LeakyReLU(0.2, inplace=True))\n            return layers\n\n        # 70x70 PatchGAN\n        self.model = nn.Sequential(\n            # C64: No normalization in first layer\n            *conv_block(in_ch, base_ch, normalize=False),        # 256 → 128\n            # C128: With normalization\n            *conv_block(base_ch, base_ch*2),                     # 128 → 64\n            # C256: With normalization\n            *conv_block(base_ch*2, base_ch*4),                   # 64 → 32\n            # C512: With normalization, stride=1\n            *conv_block(base_ch*4, base_ch*8),                   # 32 → 16\n            # Final output layer: Single channel output (patch predictions)\n            nn.Conv2d(base_ch*8, 1, kernel_size=4, padding=1)    # 16 → ~14 (patch map)\n        )\n\n    def forward(self, x):\n        return self.model(x)\n",
   "metadata": {
    "trusted": true,
    "execution": {
     "iopub.status.busy": "2025-12-30T10:59:08.513137Z",
     "iopub.execute_input": "2025-12-30T10:59:08.513457Z",
     "iopub.status.idle": "2025-12-30T10:59:08.531137Z",
     "shell.execute_reply.started": "2025-12-30T10:59:08.513413Z",
     "shell.execute_reply": "2025-12-30T10:59:08.530467Z"
    }
   },
   "outputs": [],
   "execution_count": 26
  },
  {
   "cell_type": "code",
   "source": "def init_weights(net, init_type='normal', gain=0.02):\n    def init_func(m):\n        classname = m.__class__.__name__\n        if hasattr(m, 'weight') and (classname.find('Conv') != -1 or classname.find('Linear') != -1):\n            init.normal_(m.weight.data, 0.0, gain)\n            if hasattr(m, 'bias') and m.bias is not None:\n                init.constant_(m.bias.data, 0.0)\n        elif classname.find('BatchNorm2d') != -1:\n            init.normal_(m.weight.data, 1.0, gain)\n            init.constant_(m.bias.data, 0.0)\n    net.apply(init_func)",
   "metadata": {
    "trusted": true,
    "execution": {
     "iopub.status.busy": "2025-12-30T10:59:08.531979Z",
     "iopub.execute_input": "2025-12-30T10:59:08.532227Z",
     "iopub.status.idle": "2025-12-30T10:59:08.548051Z",
     "shell.execute_reply.started": "2025-12-30T10:59:08.532205Z",
     "shell.execute_reply": "2025-12-30T10:59:08.547352Z"
    }
   },
   "outputs": [],
   "execution_count": 27
  },
  {
   "cell_type": "code",
   "source": "def load_checkpoint(ckpt_path, map_location=None):\n    ckpt = torch.load(ckpt_path, map_location=map_location, weights_only=False)\n    print(' [*] Loading checkpoint from %s succeed!' % ckpt_path)\n    return ckpt",
   "metadata": {
    "trusted": true,
    "execution": {
     "iopub.status.busy": "2025-12-30T10:59:08.548946Z",
     "iopub.execute_input": "2025-12-30T10:59:08.549189Z",
     "iopub.status.idle": "2025-12-30T10:59:08.561893Z",
     "shell.execute_reply.started": "2025-12-30T10:59:08.549168Z",
     "shell.execute_reply": "2025-12-30T10:59:08.561174Z"
    }
   },
   "outputs": [],
   "execution_count": 28
  },
  {
   "cell_type": "code",
   "source": "class CycleGAN(object):\n    def __init__(self, in_ch, out_ch, epochs, device, start_lr=2e-4, lmbda=10, idt_coef=0.5, adv_coef=1.0, decay_epoch=0):\n        self.epochs = epochs\n        self.decay_epoch = decay_epoch if decay_epoch > 0 else int(self.epochs/2)\n        self.lmbda = lmbda\n        self.idt_coef = idt_coef\n        self.adv_coef = adv_coef\n        self.device = device\n        self.gen_mtp = Generator(in_ch, out_ch)\n        self.gen_ptm = Generator(in_ch, out_ch)\n        self.desc_m = Discriminator(in_ch)\n        self.desc_p = Discriminator(in_ch)\n        self.init_models()\n        self.mse_loss = nn.MSELoss()\n        self.l1_loss = nn.L1Loss()\n        self.adam_gen = torch.optim.Adam(itertools.chain(self.gen_mtp.parameters(), self.gen_ptm.parameters()),\n                                         lr = start_lr, betas=(0.5, 0.999))\n        self.adam_desc = torch.optim.Adam(itertools.chain(self.desc_m.parameters(), self.desc_p.parameters()),\n                                          lr=start_lr, betas=(0.5, 0.999))\n        self.start_epoch = 0\n\n    def init_models(self):\n        init_weights(self.gen_mtp)\n        init_weights(self.gen_ptm)\n        init_weights(self.desc_m)\n        init_weights(self.desc_p)\n        self.gen_mtp = self.gen_mtp.to(self.device)\n        self.gen_ptm = self.gen_ptm.to(self.device)\n        self.desc_m = self.desc_m.to(self.device)\n        self.desc_p = self.desc_p.to(self.device)\n\n    def load_weights(self, ckpt_path):\n        ckpt = load_checkpoint(ckpt_path)\n        self.start_epoch = ckpt['epoch']\n        self.gen_mtp.load_state_dict(ckpt['gen_mtp'])\n        self.gen_ptm.load_state_dict(ckpt['gen_ptm'])",
   "metadata": {
    "trusted": true,
    "execution": {
     "iopub.status.busy": "2025-12-30T10:59:08.578647Z",
     "iopub.execute_input": "2025-12-30T10:59:08.578964Z",
     "iopub.status.idle": "2025-12-30T10:59:08.597155Z",
     "shell.execute_reply.started": "2025-12-30T10:59:08.578901Z",
     "shell.execute_reply": "2025-12-30T10:59:08.596262Z"
    }
   },
   "outputs": [],
   "execution_count": 30
  },
  {
   "cell_type": "markdown",
   "source": "## Load model",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": "device = torch.device('cuda')\n\ndef load_my_model(path):\n    # 1. Initialize the architecture\n    model = CycleGAN(3, 3, 1, device)\n    \n    # 2. Load the weights\n    model.load_weights(path)\n\n    return model",
   "metadata": {
    "trusted": true,
    "execution": {
     "iopub.status.busy": "2025-12-30T10:59:08.599193Z",
     "iopub.execute_input": "2025-12-30T10:59:08.599518Z",
     "iopub.status.idle": "2025-12-30T10:59:08.614654Z",
     "shell.execute_reply.started": "2025-12-30T10:59:08.599471Z",
     "shell.execute_reply": "2025-12-30T10:59:08.613963Z"
    }
   },
   "outputs": [],
   "execution_count": 31
  },
  {
   "cell_type": "code",
   "source": "import glob\n\ncheckpoint_dir = '/kaggle/working'\nos.makedirs(checkpoint_dir, exist_ok=True)\n\ncheckpoints = glob.glob(os.path.join(checkpoint_dir, '*.ckpt'))",
   "metadata": {
    "trusted": true,
    "execution": {
     "iopub.status.busy": "2025-12-30T10:59:08.615398Z",
     "iopub.execute_input": "2025-12-30T10:59:08.615650Z",
     "iopub.status.idle": "2025-12-30T10:59:08.632157Z",
     "shell.execute_reply.started": "2025-12-30T10:59:08.615618Z",
     "shell.execute_reply": "2025-12-30T10:59:08.631680Z"
    }
   },
   "outputs": [],
   "execution_count": 32
  },
  {
   "cell_type": "code",
   "source": "model = load_my_model(checkpoints[0])",
   "metadata": {
    "trusted": true,
    "execution": {
     "iopub.status.busy": "2025-12-30T10:59:08.633071Z",
     "iopub.execute_input": "2025-12-30T10:59:08.633343Z",
     "iopub.status.idle": "2025-12-30T10:59:11.317478Z",
     "shell.execute_reply.started": "2025-12-30T10:59:08.633313Z",
     "shell.execute_reply": "2025-12-30T10:59:11.316713Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "text": " [*] Loading checkpoint from /kaggle/working/U-Net.ckpt succeed!\n",
     "output_type": "stream"
    }
   ],
   "execution_count": 33
  },
  {
   "cell_type": "markdown",
   "source": "## DataLoader",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": "class ImageDataset(Dataset):\n    def __init__(self, photo_dir, size=(256, 256), normalize=True):\n        super().__init__()\n        self.photo_dir = photo_dir\n\n        self.photo_filenames = os.listdir(self.photo_dir)\n\n        layers = [transforms.Resize(size), transforms.ToTensor()]\n        if normalize:\n            layers.append(transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)))\n        self.transform = transforms.Compose(layers)\n\n        self.photo_len = len(self.photo_filenames)\n\n    def __getitem__(self, idx):\n        photo_path = os.path.join(self.photo_dir, self.photo_filenames[idx % self.photo_len])\n\n        photo_img = self.transform(Image.open(photo_path).convert(\"RGB\"))\n\n        return photo_img\n\n    def __len__(self):\n        return self.photo_len",
   "metadata": {
    "trusted": true,
    "execution": {
     "iopub.status.busy": "2025-12-30T10:59:15.984568Z",
     "iopub.execute_input": "2025-12-30T10:59:15.985290Z",
     "iopub.status.idle": "2025-12-30T10:59:15.991297Z",
     "shell.execute_reply.started": "2025-12-30T10:59:15.985260Z",
     "shell.execute_reply": "2025-12-30T10:59:15.990461Z"
    }
   },
   "outputs": [],
   "execution_count": 34
  },
  {
   "cell_type": "code",
   "source": "img_ds = ImageDataset('/kaggle/input/gan-getting-started/photo_jpg/', normalize=False)",
   "metadata": {
    "trusted": true,
    "execution": {
     "iopub.status.busy": "2025-12-30T10:59:18.485193Z",
     "iopub.execute_input": "2025-12-30T10:59:18.485796Z",
     "iopub.status.idle": "2025-12-30T10:59:18.492950Z",
     "shell.execute_reply.started": "2025-12-30T10:59:18.485767Z",
     "shell.execute_reply": "2025-12-30T10:59:18.492225Z"
    }
   },
   "outputs": [],
   "execution_count": 35
  },
  {
   "cell_type": "code",
   "source": "img_dl = DataLoader(img_ds, batch_size=1, pin_memory=True)",
   "metadata": {
    "trusted": true,
    "execution": {
     "iopub.status.busy": "2025-12-30T11:43:14.108983Z",
     "iopub.execute_input": "2025-12-30T11:43:14.109571Z",
     "iopub.status.idle": "2025-12-30T11:43:14.112931Z",
     "shell.execute_reply.started": "2025-12-30T11:43:14.109544Z",
     "shell.execute_reply": "2025-12-30T11:43:14.112248Z"
    }
   },
   "outputs": [],
   "execution_count": 50
  },
  {
   "cell_type": "code",
   "source": "def unnorm(img, mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5]):\n    for t, m, s in zip(img, mean, std):\n        t.mul_(s).add_(s)\n\n    return img",
   "metadata": {
    "trusted": true,
    "execution": {
     "iopub.status.busy": "2025-12-30T11:43:15.497531Z",
     "iopub.execute_input": "2025-12-30T11:43:15.498248Z",
     "iopub.status.idle": "2025-12-30T11:43:15.502423Z",
     "shell.execute_reply.started": "2025-12-30T11:43:15.498220Z",
     "shell.execute_reply": "2025-12-30T11:43:15.501743Z"
    }
   },
   "outputs": [],
   "execution_count": 51
  },
  {
   "cell_type": "code",
   "source": "import matplotlib.pyplot as plt\n\ndef show_image(photo_img, monet_img):\n    f = plt.figure(figsize=(5, 5))\n    \n    f.add_subplot(1, 2, 1)\n    plt.title('Photo')\n    plt.imshow(photo_img[0].permute(1, 2, 0))\n    \n    f.add_subplot(1, 2, 2)\n    plt.title('Monet')\n    monet_img = unnorm(monet_img)\n    plt.imshow(monet_img[0].permute(1, 2, 0))",
   "metadata": {
    "trusted": true,
    "execution": {
     "iopub.status.busy": "2025-12-30T11:43:15.667041Z",
     "iopub.execute_input": "2025-12-30T11:43:15.667273Z",
     "iopub.status.idle": "2025-12-30T11:43:15.671768Z",
     "shell.execute_reply.started": "2025-12-30T11:43:15.667253Z",
     "shell.execute_reply": "2025-12-30T11:43:15.671065Z"
    }
   },
   "outputs": [],
   "execution_count": 52
  },
  {
   "cell_type": "code",
   "source": "# Create a directory for images\nos.makedirs('../images', exist_ok=True)\n\nit = iter(img_dl)\nprint(len(it))\n# Generate 7,000+ images\nphoto_path = '/kaggle/input/gan-getting-started/photo_jpg/'\nfor i in range(len(it)):\n    # Preprocess, Predict with model, Postprocess\n    photo_img = next(it)\n    \n    pred_monet = model.gen_ptm(photo_img.to(device)).cpu().detach()\n    # show_image(photo_img, pred_monet)\n    # Save as JPG\n    img_array = pred_monet[0].permute(1, 2, 0).numpy()\n    img_array = (img_array * 255).clip(0, 255).astype('uint8')\n    im = Image.fromarray(img_array)\n    im.save(f\"../images/{i+1}.jpg\")\n    if (i + 1) % 500 == 0:\n        print(f'{i + 1} is generated')\n",
   "metadata": {
    "trusted": true,
    "execution": {
     "iopub.status.busy": "2025-12-30T11:43:23.384969Z",
     "iopub.execute_input": "2025-12-30T11:43:23.385686Z",
     "iopub.status.idle": "2025-12-30T11:44:41.751102Z",
     "shell.execute_reply.started": "2025-12-30T11:43:23.385659Z",
     "shell.execute_reply": "2025-12-30T11:44:41.750478Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "text": "7038\n500 is generated\n1000 is generated\n1500 is generated\n2000 is generated\n2500 is generated\n3000 is generated\n3500 is generated\n4000 is generated\n4500 is generated\n5000 is generated\n5500 is generated\n6000 is generated\n6500 is generated\n7000 is generated\n",
     "output_type": "stream"
    }
   ],
   "execution_count": 54
  },
  {
   "cell_type": "code",
   "source": "import shutil\nimport os\n\n# Define the folder path\nfolder_to_zip = '../images'\noutput_filename = 'images' # Will result in images.zip\n\n# Use shutil for a more 'Pythonic' and robust zipping process\nshutil.make_archive(output_filename, 'zip', folder_to_zip)\n\nprint(f\"Zip complete! Archive size: {os.path.getsize('images.zip') / 1024**2:.2f} MB\")",
   "metadata": {
    "trusted": true,
    "execution": {
     "iopub.status.busy": "2025-12-30T11:44:58.117460Z",
     "iopub.execute_input": "2025-12-30T11:44:58.118027Z",
     "iopub.status.idle": "2025-12-30T11:45:02.702622Z",
     "shell.execute_reply.started": "2025-12-30T11:44:58.118001Z",
     "shell.execute_reply": "2025-12-30T11:45:02.701957Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "text": "Zip complete! Archive size: 143.80 MB\n",
     "output_type": "stream"
    }
   ],
   "execution_count": 55
  },
  {
   "cell_type": "code",
   "source": "",
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "execution_count": null
  }
 ]
}
