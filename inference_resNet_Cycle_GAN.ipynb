{
 "metadata": {
  "kernelspec": {
   "language": "python",
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.12.12",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "sourceId": 21755,
     "databundleVersionId": 1475600,
     "sourceType": "competition"
    }
   ],
   "dockerImageVersionId": 31234,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook",
   "isGpuEnabled": true
  }
 },
 "nbformat_minor": 4,
 "nbformat": 4,
 "cells": [
  {
   "cell_type": "code",
   "source": "# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\n# for dirname, _, filenames in os.walk('/kaggle/input'):\n#     for filename in filenames:\n#         print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session",
   "metadata": {
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "trusted": true,
    "_kg_hide-output": true,
    "_kg_hide-input": true,
    "execution": {
     "iopub.status.busy": "2025-12-28T14:20:11.653580Z",
     "iopub.execute_input": "2025-12-28T14:20:11.653853Z",
     "iopub.status.idle": "2025-12-28T14:20:11.657995Z",
     "shell.execute_reply.started": "2025-12-28T14:20:11.653832Z",
     "shell.execute_reply": "2025-12-28T14:20:11.657319Z"
    }
   },
   "outputs": [],
   "execution_count": 21
  },
  {
   "cell_type": "code",
   "source": "import zipfile\nfrom PIL import Image\n\nimport itertools\n\nimport torch\nimport torch.nn as nn\nimport torch.nn.init as init\nimport torchvision.transforms as transforms\n\nfrom torch.utils.data import Dataset, random_split, DataLoader",
   "metadata": {
    "trusted": true,
    "execution": {
     "iopub.status.busy": "2025-12-28T14:20:11.659919Z",
     "iopub.execute_input": "2025-12-28T14:20:11.660215Z",
     "iopub.status.idle": "2025-12-28T14:20:11.673457Z",
     "shell.execute_reply.started": "2025-12-28T14:20:11.660195Z",
     "shell.execute_reply": "2025-12-28T14:20:11.672831Z"
    }
   },
   "outputs": [],
   "execution_count": 22
  },
  {
   "cell_type": "code",
   "source": [
    "!pip install gdown\n",
    "import gdown\n",
    "url = 'https://drive.google.com/file/d/1Pngq97neXTthfB6TO3_c_58gFGrm8jAK/view?usp=sharing'\n",
    "!gdown --id 1Pngq97neXTthfB6TO3_c_58gFGrm8jAK -O ResNet.ckpt"
   ],
   "metadata": {
    "trusted": true,
    "execution": {
     "iopub.status.busy": "2025-12-28T14:20:11.674453Z",
     "iopub.execute_input": "2025-12-28T14:20:11.674721Z",
     "iopub.status.idle": "2025-12-28T14:20:18.492017Z",
     "shell.execute_reply.started": "2025-12-28T14:20:11.674695Z",
     "shell.execute_reply": "2025-12-28T14:20:18.491040Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "text": "Requirement already satisfied: gdown in /usr/local/lib/python3.12/dist-packages (5.2.0)\nRequirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.12/dist-packages (from gdown) (4.13.5)\nRequirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from gdown) (3.20.1)\nRequirement already satisfied: requests[socks] in /usr/local/lib/python3.12/dist-packages (from gdown) (2.32.5)\nRequirement already satisfied: tqdm in /usr/local/lib/python3.12/dist-packages (from gdown) (4.67.1)\nRequirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.12/dist-packages (from beautifulsoup4->gdown) (2.8)\nRequirement already satisfied: typing-extensions>=4.0.0 in /usr/local/lib/python3.12/dist-packages (from beautifulsoup4->gdown) (4.15.0)\nRequirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests[socks]->gdown) (3.4.4)\nRequirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests[socks]->gdown) (3.11)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests[socks]->gdown) (2.6.2)\nRequirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests[socks]->gdown) (2025.11.12)\nRequirement already satisfied: PySocks!=1.5.7,>=1.5.6 in /usr/local/lib/python3.12/dist-packages (from requests[socks]->gdown) (1.7.1)\n/usr/local/lib/python3.12/dist-packages/gdown/__main__.py:140: FutureWarning: Option `--id` was deprecated in version 4.3.1 and will be removed in 5.0. You don't need to pass it anymore to use a file ID.\n  warnings.warn(\nDownloading...\nFrom (original): https://drive.google.com/uc?id=18TImeANVDmgI7jc5_QkKkksc-yQABtmE\nFrom (redirected): https://drive.google.com/uc?id=18TImeANVDmgI7jc5_QkKkksc-yQABtmE&confirm=t&uuid=ba237bd5-e6aa-4dc1-8ca7-2845390b7f7a\nTo: /kaggle/working/ResNet.ckpt\n100%|█████████████████████████████████████████| 255M/255M [00:01<00:00, 212MB/s]\n",
     "output_type": "stream"
    }
   ],
   "execution_count": 23
  },
  {
   "cell_type": "markdown",
   "source": "## Model",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": "def Upsample(in_ch, out_ch, use_dropout=True, dropout_ratio=0.5):\n    if use_dropout:\n        return nn.Sequential(\n            nn.ConvTranspose2d(in_ch, out_ch, 3, stride=2, padding=1, output_padding=1),\n            nn.InstanceNorm2d(out_ch),\n            nn.Dropout(dropout_ratio),\n            nn.GELU()\n        )\n    else:\n        return nn.Sequential(\n            nn.ConvTranspose2d(in_ch, out_ch, 3, stride=2, padding=1, output_padding=1),\n            nn.InstanceNorm2d(out_ch),\n            nn.GELU()\n        )",
   "metadata": {
    "trusted": true,
    "execution": {
     "iopub.status.busy": "2025-12-28T14:20:18.493788Z",
     "iopub.execute_input": "2025-12-28T14:20:18.494047Z",
     "iopub.status.idle": "2025-12-28T14:20:18.499433Z",
     "shell.execute_reply.started": "2025-12-28T14:20:18.494019Z",
     "shell.execute_reply": "2025-12-28T14:20:18.498748Z"
    }
   },
   "outputs": [],
   "execution_count": 24
  },
  {
   "cell_type": "code",
   "source": "def Convlayer(in_ch, out_ch, kernel_size=3, stride=2, use_leaky=True, use_inst_norm=True, use_pad=True):\n    if use_pad:\n        conv = nn.Conv2d(in_ch, out_ch, kernel_size, stride, 1, bias=True)\n    else:\n        conv = nn.Conv2d(in_ch, out_ch, kernel_size, stride, 0, bias=True)\n\n    if use_leaky:\n        actv = nn.LeakyReLU(negative_slope=0.2, inplace=True)\n    else:\n        actv = nn.GELU()\n\n    if use_inst_norm:\n        norm = nn.InstanceNorm2d(out_ch)\n    else:\n        norm = nn.BatchNorm2d(out_ch)\n\n    return nn.Sequential(\n        conv,\n        norm,\n        actv\n    )",
   "metadata": {
    "trusted": true,
    "execution": {
     "iopub.status.busy": "2025-12-28T14:20:18.500356Z",
     "iopub.execute_input": "2025-12-28T14:20:18.500698Z",
     "iopub.status.idle": "2025-12-28T14:20:18.513113Z",
     "shell.execute_reply.started": "2025-12-28T14:20:18.500665Z",
     "shell.execute_reply": "2025-12-28T14:20:18.512544Z"
    }
   },
   "outputs": [],
   "execution_count": 25
  },
  {
   "cell_type": "code",
   "source": "class Resblock(nn.Module):\n    def __init__(self, in_features, use_dropout=True, dropout_ratio=0.5):\n        super().__init__()\n        layers = list()\n        layers.append(nn.ReflectionPad2d(1))\n        layers.append(Convlayer(in_features, in_features, 3, 1, False, use_pad=False))\n        layers.append(nn.Dropout(dropout_ratio))\n        layers.append(nn.ReflectionPad2d(1))\n        layers.append(nn.Conv2d(in_features, in_features, 3, 1, padding=0, bias=True))\n        layers.append(nn.InstanceNorm2d(in_features))\n        self.res = nn.Sequential(*layers)\n\n    def forward(self, x):\n        return x + self.res(x)",
   "metadata": {
    "trusted": true,
    "execution": {
     "iopub.status.busy": "2025-12-28T14:20:18.514864Z",
     "iopub.execute_input": "2025-12-28T14:20:18.515177Z",
     "iopub.status.idle": "2025-12-28T14:20:18.527005Z",
     "shell.execute_reply.started": "2025-12-28T14:20:18.515156Z",
     "shell.execute_reply": "2025-12-28T14:20:18.526315Z"
    }
   },
   "outputs": [],
   "execution_count": 26
  },
  {
   "cell_type": "code",
   "source": "class Generator(nn.Module):\n    def __init__(self, in_ch, out_ch, num_res_blocks=6):\n        super().__init__()\n        model = list()\n        model.append(nn.ReflectionPad2d(3))\n        model.append(Convlayer(in_ch, 64, 7, 1, False, True, False))\n        model.append(Convlayer(64, 128, 3, 2, False))\n        model.append(Convlayer(128, 256, 3, 2, False))\n        for _ in range(num_res_blocks):\n            model.append(Resblock(256))\n        model.append(Upsample(256, 128))\n        model.append(Upsample(128, 64))\n        model.append(nn.ReflectionPad2d(3))\n        model.append(nn.Conv2d(64, out_ch, kernel_size=7, padding=0))\n        model.append(nn.Tanh())\n\n        self.gen = nn.Sequential(*model)\n\n    def forward(self, x):\n        return self.gen(x)",
   "metadata": {
    "trusted": true,
    "execution": {
     "iopub.status.busy": "2025-12-28T14:20:18.527792Z",
     "iopub.execute_input": "2025-12-28T14:20:18.528022Z",
     "iopub.status.idle": "2025-12-28T14:20:18.540141Z",
     "shell.execute_reply.started": "2025-12-28T14:20:18.527990Z",
     "shell.execute_reply": "2025-12-28T14:20:18.539374Z"
    }
   },
   "outputs": [],
   "execution_count": 27
  },
  {
   "cell_type": "code",
   "source": "def init_weights(net, init_type='normal', gain=0.02):\n    def init_func(m):\n        classname = m.__class__.__name__\n        if hasattr(m, 'weight') and (classname.find('Conv') != -1 or classname.find('Linear') != -1):\n            init.normal_(m.weight.data, 0.0, gain)\n            if hasattr(m, 'bias') and m.bias is not None:\n                init.constant_(m.bias.data, 0.0)\n        elif classname.find('BatchNorm2d') != -1:\n            init.normal_(m.weight.data, 1.0, gain)\n            init.constant_(m.bias.data, 0.0)\n    net.apply(init_func)",
   "metadata": {
    "trusted": true,
    "execution": {
     "iopub.status.busy": "2025-12-28T14:20:18.541046Z",
     "iopub.execute_input": "2025-12-28T14:20:18.541346Z",
     "iopub.status.idle": "2025-12-28T14:20:18.558550Z",
     "shell.execute_reply.started": "2025-12-28T14:20:18.541315Z",
     "shell.execute_reply": "2025-12-28T14:20:18.557793Z"
    }
   },
   "outputs": [],
   "execution_count": 28
  },
  {
   "cell_type": "code",
   "source": "class Discriminator(nn.Module):\n    def __init__(self, in_ch, num_layers=4):\n        super().__init__()\n        model = list()\n        model.append(nn.Conv2d(in_ch, 64, 4, stride=2, padding=1))\n        model.append(nn.LeakyReLU(0.2, inplace=True))\n        for i in range(1, num_layers):\n            in_chs = 64 * 2**(i-1)\n            out_chs = in_chs * 2\n            if i == num_layers -1:\n                model.append(Convlayer(in_chs, out_chs, 4, 1))\n            else:\n                model.append(Convlayer(in_chs, out_chs, 4, 2))\n        model.append(nn.Conv2d(512, 1, kernel_size=4, stride=1, padding=1))\n        self.disc = nn.Sequential(*model)\n\n    def forward(self, x):\n        return self.disc(x)",
   "metadata": {
    "trusted": true,
    "execution": {
     "iopub.status.busy": "2025-12-28T14:20:18.559497Z",
     "iopub.execute_input": "2025-12-28T14:20:18.559771Z",
     "iopub.status.idle": "2025-12-28T14:20:18.572488Z",
     "shell.execute_reply.started": "2025-12-28T14:20:18.559742Z",
     "shell.execute_reply": "2025-12-28T14:20:18.571877Z"
    }
   },
   "outputs": [],
   "execution_count": 29
  },
  {
   "cell_type": "code",
   "source": "def load_checkpoint(ckpt_path, map_location=None):\n    ckpt = torch.load(ckpt_path, map_location=map_location, weights_only=False)\n    print(' [*] Loading checkpoint from %s succeed!' % ckpt_path)\n    return ckpt",
   "metadata": {
    "trusted": true,
    "execution": {
     "iopub.status.busy": "2025-12-28T14:20:18.573207Z",
     "iopub.execute_input": "2025-12-28T14:20:18.573473Z",
     "iopub.status.idle": "2025-12-28T14:20:18.585983Z",
     "shell.execute_reply.started": "2025-12-28T14:20:18.573453Z",
     "shell.execute_reply": "2025-12-28T14:20:18.585429Z"
    }
   },
   "outputs": [],
   "execution_count": 30
  },
  {
   "cell_type": "code",
   "source": "class CycleGAN(object):\n    def __init__(self, in_ch, out_ch, device, start_lr=2e-4, lmbda=10, idt_coef=0.5, decay_epoch=0):\n        self.epochs = 1\n        self.decay_epoch = decay_epoch if decay_epoch > 0 else int(self.epochs/2)\n        self.lmbda = lmbda\n        self.idt_coef = idt_coef\n        self.device = device\n        self.gen_mtp = Generator(in_ch, out_ch)\n        self.gen_ptm = Generator(in_ch, out_ch)\n        self.desc_m = Discriminator(in_ch)\n        self.desc_p = Discriminator(in_ch)\n        self.init_models()\n        self.mse_loss = nn.MSELoss()\n        self.l1_loss = nn.L1Loss()\n        self.adam_gen = torch.optim.Adam(itertools.chain(self.gen_mtp.parameters(), self.gen_ptm.parameters()),\n                                         lr = start_lr, betas=(0.5, 0.999))\n        self.adam_desc = torch.optim.Adam(itertools.chain(self.desc_m.parameters(), self.desc_p.parameters()),\n                                          lr=start_lr, betas=(0.5, 0.999))\n\n    def init_models(self):\n        init_weights(self.gen_mtp)\n        init_weights(self.gen_ptm)\n        init_weights(self.desc_m)\n        init_weights(self.desc_p)\n        self.gen_mtp = self.gen_mtp.to(self.device)\n        self.gen_ptm = self.gen_ptm.to(self.device)\n        self.desc_m = self.desc_m.to(self.device)\n        self.desc_p = self.desc_p.to(self.device)\n\n    def load_weights(self, ckpt_path):\n        ckpt = load_checkpoint(ckpt_path, self.device)\n        # self.start_epoch = ckpt['epoch']\n        self.gen_mtp.load_state_dict(ckpt['gen_mtp'])\n        self.gen_ptm.load_state_dict(ckpt['gen_ptm'])\n        self.desc_m.load_state_dict(ckpt['desc_m'])\n        self.desc_p.load_state_dict(ckpt['desc_p'])\n        self.adam_gen.load_state_dict(ckpt['optimizer_gen'])\n        self.adam_desc.load_state_dict(ckpt['optimizer_desc'])",
   "metadata": {
    "trusted": true,
    "execution": {
     "iopub.status.busy": "2025-12-28T14:20:18.586718Z",
     "iopub.execute_input": "2025-12-28T14:20:18.586983Z",
     "iopub.status.idle": "2025-12-28T14:20:18.604724Z",
     "shell.execute_reply.started": "2025-12-28T14:20:18.586951Z",
     "shell.execute_reply": "2025-12-28T14:20:18.604124Z"
    }
   },
   "outputs": [],
   "execution_count": 31
  },
  {
   "cell_type": "markdown",
   "source": "## Load model",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": "device = torch.device('cuda')\n\ndef load_my_model(path):\n    # 1. Initialize the architecture\n    model = CycleGAN(3, 3, device)\n    \n    # 2. Load the weights\n    model.load_weights(path)\n\n    return model",
   "metadata": {
    "trusted": true,
    "execution": {
     "iopub.status.busy": "2025-12-28T14:20:18.606914Z",
     "iopub.execute_input": "2025-12-28T14:20:18.607149Z",
     "iopub.status.idle": "2025-12-28T14:20:18.617701Z",
     "shell.execute_reply.started": "2025-12-28T14:20:18.607123Z",
     "shell.execute_reply": "2025-12-28T14:20:18.617138Z"
    }
   },
   "outputs": [],
   "execution_count": 32
  },
  {
   "cell_type": "code",
   "source": "import glob\n\ncheckpoint_dir = '/kaggle/working'\nos.makedirs(checkpoint_dir, exist_ok=True)\n\ncheckpoints = glob.glob(os.path.join(checkpoint_dir, '*.ckpt'))",
   "metadata": {
    "trusted": true,
    "execution": {
     "iopub.status.busy": "2025-12-28T14:20:18.618469Z",
     "iopub.execute_input": "2025-12-28T14:20:18.618766Z",
     "iopub.status.idle": "2025-12-28T14:20:18.633478Z",
     "shell.execute_reply.started": "2025-12-28T14:20:18.618738Z",
     "shell.execute_reply": "2025-12-28T14:20:18.632927Z"
    }
   },
   "outputs": [],
   "execution_count": 33
  },
  {
   "cell_type": "code",
   "source": "model = load_my_model(checkpoints[0])",
   "metadata": {
    "trusted": true,
    "execution": {
     "iopub.status.busy": "2025-12-28T14:20:18.634105Z",
     "iopub.execute_input": "2025-12-28T14:20:18.634346Z",
     "iopub.status.idle": "2025-12-28T14:20:19.192909Z",
     "shell.execute_reply.started": "2025-12-28T14:20:18.634326Z",
     "shell.execute_reply": "2025-12-28T14:20:19.192264Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "text": " [*] Loading checkpoint from /kaggle/working/ResNet.ckpt succeed!\n",
     "output_type": "stream"
    }
   ],
   "execution_count": 34
  },
  {
   "cell_type": "markdown",
   "source": "## DataLoader",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": "class ImageDataset(Dataset):\n    def __init__(self, photo_dir, size=(256, 256), normalize=True):\n        super().__init__()\n        self.photo_dir = photo_dir\n        self.photo_idx = dict()\n        if normalize:\n            self.transform = transforms.Compose([\n                transforms.Resize(size),\n                transforms.ToTensor(),\n                transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n            ])\n        else:\n            self.transform = transforms.Compose([\n                transforms.Resize(size),\n                transforms.ToTensor()\n            ])\n        for i, fl in enumerate(os.listdir(self.photo_dir)):\n            self.photo_idx[i] = fl\n\n    def __getitem__(self, idx):\n        img_name = self.photo_idx[idx]\n        photo_path = os.path.join(self.photo_dir, img_name)\n        \n        photo_img = Image.open(photo_path)\n        photo_img = self.transform(photo_img)\n        \n        return photo_img\n\n    def __len__(self):\n        return len(self.photo_idx.keys())",
   "metadata": {
    "trusted": true,
    "execution": {
     "iopub.status.busy": "2025-12-28T14:20:19.193717Z",
     "iopub.execute_input": "2025-12-28T14:20:19.193966Z",
     "iopub.status.idle": "2025-12-28T14:20:19.200074Z",
     "shell.execute_reply.started": "2025-12-28T14:20:19.193945Z",
     "shell.execute_reply": "2025-12-28T14:20:19.199370Z"
    }
   },
   "outputs": [],
   "execution_count": 35
  },
  {
   "cell_type": "code",
   "source": "img_ds = ImageDataset('/kaggle/input/gan-getting-started/photo_jpg/', normalize=False)",
   "metadata": {
    "trusted": true,
    "execution": {
     "iopub.status.busy": "2025-12-28T14:20:19.201000Z",
     "iopub.execute_input": "2025-12-28T14:20:19.201271Z",
     "iopub.status.idle": "2025-12-28T14:20:19.221297Z",
     "shell.execute_reply.started": "2025-12-28T14:20:19.201250Z",
     "shell.execute_reply": "2025-12-28T14:20:19.220606Z"
    }
   },
   "outputs": [],
   "execution_count": 36
  },
  {
   "cell_type": "code",
   "source": "img_dl = DataLoader(img_ds, batch_size=1, pin_memory=True)",
   "metadata": {
    "trusted": true,
    "execution": {
     "iopub.status.busy": "2025-12-28T14:20:19.222272Z",
     "iopub.execute_input": "2025-12-28T14:20:19.222586Z",
     "iopub.status.idle": "2025-12-28T14:20:19.226616Z",
     "shell.execute_reply.started": "2025-12-28T14:20:19.222566Z",
     "shell.execute_reply": "2025-12-28T14:20:19.225953Z"
    }
   },
   "outputs": [],
   "execution_count": 37
  },
  {
   "cell_type": "code",
   "source": "def unnorm(img, mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5]):\n    for t, m, s in zip(img, mean, std):\n        t.mul_(s).add_(s)\n\n    return img",
   "metadata": {
    "trusted": true,
    "execution": {
     "iopub.status.busy": "2025-12-28T14:20:19.227488Z",
     "iopub.execute_input": "2025-12-28T14:20:19.227970Z",
     "iopub.status.idle": "2025-12-28T14:20:19.239871Z",
     "shell.execute_reply.started": "2025-12-28T14:20:19.227948Z",
     "shell.execute_reply": "2025-12-28T14:20:19.239256Z"
    }
   },
   "outputs": [],
   "execution_count": 38
  },
  {
   "cell_type": "code",
   "source": "import matplotlib.pyplot as plt\n\ndef show_image(photo_img, monet_img):\n    f = plt.figure(figsize=(5, 5))\n    \n    f.add_subplot(1, 2, 1)\n    plt.title('Photo')\n    photo_img = unnorm(photo_img)\n    plt.imshow(photo_img[0].permute(1, 2, 0))\n    \n    f.add_subplot(1, 2, 2)\n    plt.title('Monet')\n    monet_img = unnorm(monet_img)\n    plt.imshow(monet_img[0].permute(1, 2, 0))",
   "metadata": {
    "trusted": true,
    "execution": {
     "iopub.status.busy": "2025-12-28T14:20:19.240610Z",
     "iopub.execute_input": "2025-12-28T14:20:19.240898Z",
     "iopub.status.idle": "2025-12-28T14:20:19.255008Z",
     "shell.execute_reply.started": "2025-12-28T14:20:19.240867Z",
     "shell.execute_reply": "2025-12-28T14:20:19.254286Z"
    }
   },
   "outputs": [],
   "execution_count": 39
  },
  {
   "cell_type": "code",
   "source": [
    "# Create a directory for images\n",
    "os.makedirs('../images', exist_ok=True)\n",
    "\n",
    "it = iter(img_dl)\n",
    "print(len(it))\n",
    "# Generate 7,000+ images\n",
    "photo_path = '/kaggle/input/gan-getting-started/photo_jpg/'\n",
    "for i in range(len(it)):\n",
    "    # Preprocess, Predict with model, Postprocess\n",
    "    photo_img = next(it)\n",
    "    \n",
    "    pred_monet = model.gen_ptm(photo_img.to(device)).cpu().detach()\n",
    "    # show_image(photo_img, pred_monet)\n",
    "    # Save as JPG\n",
    "    img_array = pred_monet[0].permute(1, 2, 0).numpy()\n",
    "    img_array = (img_array * 255).clip(0, 255).astype('uint8')\n",
    "    im = Image.fromarray(img_array)\n",
    "    im.save(f\"../images/{i+1}.jpg\")\n",
    "    if (i + 1) % 500 == 0:\n",
    "        print(f'{i + 1} is generated')\n"
   ],
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "import shutil\n",
    "import os\n",
    "\n",
    "# Define the folder path\n",
    "folder_to_zip = '../images'\n",
    "output_filename = 'images' # Will result in images.zip\n",
    "\n",
    "# Use shutil for a more 'Pythonic' and robust zipping process\n",
    "shutil.make_archive(output_filename, 'zip', folder_to_zip)\n",
    "\n",
    "print(f\"Zip complete! Archive size: {os.path.getsize('images.zip') / 1024**2:.2f} MB\")"
   ],
   "metadata": {
    "trusted": true,
    "execution": {
     "iopub.status.busy": "2025-12-28T14:21:00.021327Z",
     "iopub.status.idle": "2025-12-28T14:21:00.021611Z",
     "shell.execute_reply.started": "2025-12-28T14:21:00.021492Z",
     "shell.execute_reply": "2025-12-28T14:21:00.021507Z"
    }
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": "",
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "execution_count": null
  }
 ]
}
